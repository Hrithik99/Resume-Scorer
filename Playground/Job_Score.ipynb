{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import csv\n",
    "\n",
    "env_path = 'Config.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# OpenAI API Key (Replace with your own)\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading .env from: c:\\ResumeFeedback\\Playground\\Config.env\n",
      "API Key: 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\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Manually load `.env` file using absolute path\n",
    "env_path = os.path.abspath(\"Config.env\")\n",
    "print(f\"Loading .env from: {env_path}\")  # Debugging print\n",
    "\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# Fetch API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"API Key:\", api_key)  # Debugging print\n",
    "\n",
    "#openai.api_key = api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance scores added and saved to 'updated_jobs.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the structured resume from file\n",
    "with open(\"Master_Resume_for_LLM.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    master_resume = file.read()\n",
    "\n",
    "def get_job_relevance_score(job_title, company_name, job_description):\n",
    "    \"\"\"Rates job relevance out of 10 using OpenAI API.\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are an experienced technical recruiter evaluating a candidate's resume against a job description.\n",
    "    Provide a **relevance rating out of 10** and a brief explanation.\n",
    "\n",
    "    **Job Details:**\n",
    "    - **Job Title:** {job_title}\n",
    "    - **Company:** {company_name}\n",
    "    - **Job Description:** {job_description}\n",
    "\n",
    "    **Candidate’s Resume:**\n",
    "    {master_resume}\n",
    "\n",
    "    ### **Evaluation Criteria:**\n",
    "    1. **Skill Match (0-3 points)** – Does the candidate’s skillset align with the job requirements?\n",
    "    2. **Experience Relevance (0-3 points)** – How well does the candidate's past experience match the role?\n",
    "    3. **Industry Fit (0-2 points)** – Does the candidate's background align with the company's industry?\n",
    "    4. **Role-Specific Expertise (0-2 points)** – Does the candidate demonstrate domain expertise?\n",
    "\n",
    "    ### **Output Format:**\n",
    "    Provide the rating as follows:\n",
    "    **Relevance Score:** X/10  \n",
    "    **Reasoning:** (Briefly explain the rating.)\n",
    "\n",
    "    Now, analyze the candidate’s profile and provide a structured rating.\n",
    "    \"\"\"\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are an expert recruiter evaluating job candidates.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    output_text = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    # Extract the relevance score from the response (assuming format \"**Relevance Score:** X/10\")\n",
    "    try:\n",
    "        score = int(output_text.split(\"**Relevance Score:**\")[1].split(\"/10\")[0].strip())\n",
    "    except Exception:\n",
    "        score = \"N/A\"  # Handle extraction failures\n",
    "\n",
    "    return score, output_text  # Return score and reasoning\n",
    "\n",
    "# Load your jobs DataFrame\n",
    "df = pd.read_csv(\"jobs.csv\")\n",
    "\n",
    "# Select relevant columns\n",
    "df_upd = df[['id', 'title', 'company', 'location', 'job_level', 'description']].copy()\n",
    "\n",
    "# Initialize new columns\n",
    "df_upd[\"Relevance Score gpt4.0\"] = None\n",
    "df_upd[\"Relevance Explanation gpt4.0\"] = None\n",
    "\n",
    "# Iterate row-wise and update the DataFrame\n",
    "for index, row in df_upd.iterrows():\n",
    "    job_title = row[\"title\"]\n",
    "    company_name = row[\"company\"]\n",
    "    job_description = row[\"description\"]\n",
    "\n",
    "    score, explanation = get_job_relevance_score(job_title, company_name, job_description)\n",
    "    \n",
    "    df_upd.at[index, \"Relevance Score gpt4.0\"] = score\n",
    "    df_upd.at[index, \"Relevance Explanation gpt4.0\"] = explanation\n",
    "\n",
    "# Save updated DataFrame\n",
    "df_upd.to_csv(\"updated_jobs_gpt4.csv\", index=False)\n",
    "\n",
    "print(\"Relevance scores added and saved to 'updated_jobs.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
